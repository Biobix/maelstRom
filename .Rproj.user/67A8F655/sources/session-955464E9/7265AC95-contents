##########################################################
##################### LOAD LIBRARIES #####################
##########################################################

library("MAGE")
library(edgeR)


##########################################################
####################### LOAD DATA ########################
##########################################################

# Genotyping performance is evaluated on the control sample dataset.
# You can also genotype cancer samples, of course,
# though this is expected to be a bit harder due to cancer's effects on RNA expression

load("data_allchr_control.RData")


##########################################################
############## CALCULATE GLOBAL PARAMETERS ###############
##########################################################

# The global parameters SE (sequencing error) and F (inbreeding)
# should be kept constant across all loci.
# To this end, we estimate them via fast, unshifted fits across all loci
# using MAGE's estimate_parameters_BetaBinom() function

# We first define some settings-parameter of the estimate_parameters_BetaBinom() function

NoSH <- TRUE # NoSplitHom; setting this to TRUE doesn't allow fitted beta-binomial peaks for homozygoted to be bimodal 
thetaI <- "moment" # How initial theta (overdispersion) estimates should be calculated; "moment" uses a moment estimator and is the fastest...
ReEstT <- "moment" # Whether and how initial theta-values should be re-estimated before using them as 
                   # initial value inputs for the numerical optimization procedures in the EM algorithm

# We also define some filter criteria so as to estimate SE and F using "reliable" loci only

pA_filt <- 0.15 # Loci with a very low minor allele frequency are less reliable, especially to estimate F
SE_filt <- 0.035 # Loci for which the fitting procedure returns a high sequencing error are suspicious as well...

# We then define a function for the parallel function to work with,
# speeding up this fitting process

GlobalEstFun <- function(data){
  
  SE_all <- c() # vector to hold SE estimates
  F_all <- c() # vector to hold F estimates
  
  positions <- hash::keys(data)
  
  for (z in positions) {
    #Fest_results <- MAGE::estimate_parameters_BetaBinom(ref_counts = data[[z]]$ref_count, var_counts = data[[z]]$var_count, deltaF = 10^-8, maxIT = 100, 
    #                                              SE_prior = 0.002, F_inbr_prior = NULL, HetProb = 0.5, NoSplitHom = NoSH, 
    #                                              thetaInit = thetaI, ReEstThetas = ReEstT)
    Fest_results <- MAGE::estimate_parameters(ref_counts = data[[z]]$ref_count, var_counts = data[[z]]$var_count, deltaF = 10^-8, maxIT = 100, 
                                              SE_prior = 0.002, F_inbr_prior = NULL, HetProb = 0.5)
    #data[[z]]$theta_hom_Ffit <- Fest_results$theta_hom
    #data[[z]]$theta_het_Ffit <- Fest_results$theta_het
    #data[[z]]$theta_hom_init <- Fest_results$theta_hom_init
    #data[[z]]$theta_het_init <- Fest_results$theta_het_init
    data[[z]]$nrep <- Fest_results$nrep
    data[[z]]$allelefreq <- Fest_results$allelefreq
    data[[z]]$est_SE <- Fest_results$SE
    data[[z]]$est_inbr <- Fest_results$F_inbr
    data[[z]]$genotype_SEM <- Fest_results$genotypes
    TS <- Fest_results$genoprobs
    colnames(TS) <- c("p(rr)_MetaParFit", "p(rv)_MetaParFit", "p(vv)_MetaParFit")
    data[[z]]<-cbind(data[[z]], TS)
    if (!(Fest_results$allelefreq <= pA_filt || Fest_results$allelefreq >= (1 - pA_filt) || Fest_results$SE > SE_filt) & 
        nrow(data[[z]])>=40 & median(data[[z]]$ref_count + data[[z]]$var_count) >= 5) {
      # We'll estimate SE and F based on "reliable" data BUT don't thw-row this data out, instead re-analyzing it later;
      # the more complex shifted beta-binomial model might fit this data better...
      SE_all <- c(SE_all, Fest_results$SE)
      F_all <- c(F_all, Fest_results$F_inbr)
    }
    
    # AS A LITTLE EXTRA FOR THE PAPER, I'll also do a fit using the old estimate_parameters();
    # this function performs a fit as described by seqem (i.e. unshifted regular binomial),
    # and as such might be a handy point of reference for the paper.
    
    #Fest_results_SEM <- MAGE::estimate_parameters(ref_counts = data[[z]]$ref_count, var_counts = data[[z]]$var_count, deltaF = 10^-8, maxIT = 100, 
    #                                        SE_prior = 0.002, F_inbr_prior = NULL, HetProb = 0.5)
    #data[[z]]$genotype_SEM <- Fest_results_SEM$genotypes
    
  }
  
  return(list(data, SE_all, F_all))
  
}

# Now for the actual (parallel) fitting

cl <- parallel::makeCluster(getOption("cl.cores", 22))
parallel::clusterExport(cl, c("NoSH", "thetaI", "ReEstT", "pA_filt", "SE_filt"))
GenoInterData <- parallel::parLapply(cl, X = data_allchr_control, fun = GlobalEstFun)
parallel::stopCluster(cl)

SE_allvec <- c()
F_allvec <- c()

for(i in 1:22){
  SE_allvec <- c(SE_allvec, (GenoInterData[[i]])[[2]])
  F_allvec <- c(F_allvec, (GenoInterData[[i]])[[3]])
}

#save("GenoInterData", file="GenoInterBackup.RData")

GenoInterData <- lapply(GenoInterData, `[[`, 1)

SEmedian <- median(SE_allvec)
Fmedian <- median(F_allvec)

save(list = c("SEmedian", "Fmedian"), file = "GlobalParamEst.RData")


##########################################################
################### ACTUAL GENOTYPING ####################
##########################################################

# 


RunDistRob <- "Cook"
RunCookMargin <- 5


BetaBinomGenotyping <- function(data){
  positions <- names(data)
  results <- data.frame()
  for (z in positions) {
    lrt_results <- MAGE::lrt_eqtl_BetaBinom_DistRob(data_counts = data[[z]], allelefreq = data[[z]]$allelefreq[1], SE = SEmedian,
                                      inbr = Fmedian, dltaco = 10^-6, HWE = FALSE, p_InitEst = FALSE, ThetaInits = "moment", 
                                      ReEstThetas = "moment", NoSplitHom = TRUE, NoSplitHet = TRUE, DistRob = RunDistRob, CookMargin = RunCookMargin, 
                                      NumHetMin = 5, MaxOutFrac = 0.5, fitH0 = TRUE)
                                      
    data[[z]]<-lrt_results$data_hash
    med_ase <- MAGE::median_eqtl(data[[z]]$ref_count, data[[z]]$var_count, data[[z]]$allelefreq[1], Fmedian) # calculates a median shift
    
    results_z <- data.frame("position" = z, "gene" = data[[z]]$gene[1], "probshift" = as.numeric(lrt_results$AE), 
                            "LRT" = as.numeric(lrt_results$AE_lrt), "p" = as.numeric(lrt_results$AE_p), "quality" = lrt_results$quality, 
                            "allele.frequency" = data[[z]]$allelefreq[1], "dbSNP" = data[[z]]$dbSNP_ref[1], 
                            "reference" = data[[z]]$ref[1], "variant" = data[[z]]$var[1], "est_SE" = data[[z]]$est_SE[1], 
                            "coverage" = data[[z]]$coverage[1], "nr_samples" = nrow(data[[z]]), "GOF" = lrt_results$GOF, 
                            "GOFaltMEAN" = lrt_results$GOFaltMEAN, "GOFaltMEDIAN" = lrt_results$GOFaltMEDIAN, 
                            "GOFaltPERDIST" = lrt_results$GOFaltPERDIST, "GOFaltONLYHET" = lrt_results$GOFaltONLYHET, 
                            "GOFexactMEAN" = lrt_results$GOFexactMEAN, "GOFexactMEANLOG" = lrt_results$GOFexactMEANLOG, 
                            "median_ASE" = med_ase, "est_inbreeding" = data[[z]]$est_inbr[1], "tot_inbreeding" = Fmedian, 
                            "nrep_lrt" = as.numeric(lrt_results$nrep), "nrep_first" = data[[z]]$nrep[1], 
                            "theta_hom_H1" = lrt_results$theta_hom_H1, "theta_het_H1" = lrt_results$theta_het_H1,
                            "Nagelkerke" = lrt_results$Nagelkerke, stringsAsFactors = FALSE)
    results <- rbind(results, results_z) # results; on position per line
  }
  results <- MAGE::HWEChiSquareFunction(results, Fmedian, data)
  return(list(data, results))
}

cl <- parallel::makeCluster(getOption("cl.cores", 22))
parallel::clusterExport(cl, c("RunDistRob", "RunCookMargin", "Fmedian", "SEmedian"))
GenoFinData <- parallel::parLapply(cl, X = GenoInterData, fun = BetaBinomGenotyping)
parallel::stopCluster(cl)


