# 2. Perform one fit on the entire (non-outlying) data, i.e. all parameters shared, i.e. assuming
# no dAD; the null hypothesis in dAD detection
# Remark this uses the non-robust fitting function, since outliers were already detected.
NOdAD_fit <- MAGE::EMfit_betabinom(data_counts = CurDF[CurDF$Outlier == 0,], SE = SEmedian,
inbr = Fmedian, fitH0 = FALSE)
NOdAD_fit_DF <- NOdAD_fit$data_hash
PiH0 <- NOdAD_fit$AB
rho_rr <- NOdAD_fit$rho_rr; rho_rv <- NOdAD_fit$rho_rv; rho_vv <- NOdAD_fit$rho_vv
ThetaHomH0 <- NOdAD_fit$theta_hom; ThetaHetH0 <- NOdAD_fit$theta_het
dAD_res$PiFitH0[dAD_res$LocName == LOC] <- PiH0
dAD_res$ThetaH0[dAD_res$LocName == LOC] <- ThetaHetH0
# 3. Perform a fit on the (non-outlying) data allowing separate theta_het parameters for control-
# and case-data
FullFit <- MAGE::EMfit_betabinom_popcomb(data_counts = CurDF[CurDF$Outlier == 0,], SE = SEmedian,
inbr = Fmedian, probshift_init = PiH0)
ParamVec <- FullFit$ParamVec
dAD_res$PiFitH1[dAD_res$LocName == LOC] <- ParamVec["probshift"]
dAD_res$ThetaCTRL_H1[dAD_res$LocName == LOC] <- ParamVec["theta_het_control"]
dAD_res$ThetaCASE_H1[dAD_res$LocName == LOC] <- ParamVec["theta_het_case"]
# 4. Perform the Likelihood Ratio Test for dAD detection
# Likelihood of fit with all parameters shared:
LikTot <- MAGE::pmf_betabinomMix(CurDF[CurDF$Outlier==0,]$ref_count,
CurDF[CurDF$Outlier==0,]$var_count, probshift = PiH0, SEmedian, rho_rr, rho_vv, rho_rv,
theta_hom = ThetaHomH0, theta_het = ThetaHetH0)
# Likelihood of fit with separate theta_het (calculated in two steps because of the different theta)
LikCTRL <- MAGE::pmf_betabinomMix(CTRL_DF[CTRL_DF$Outlier==0,]$ref_count, CTRL_DF[CTRL_DF$Outlier==0,]$var_count,
probshift = ParamVec["probshift"], SEmedian, ParamVec["pr"], ParamVec["pv"], ParamVec["prv"],
theta_hom = ParamVec["theta_hom"], theta_het = ParamVec["theta_het_control"])
LikCASE <- MAGE::pmf_betabinomMix(CASE_DF[CASE_DF$Outlier==0,]$ref_count, CASE_DF[CASE_DF$Outlier==0,]$var_count,
probshift = ParamVec["probshift"], SEmedian, ParamVec["pr"], ParamVec["pv"], ParamVec["prv"],
theta_hom = ParamVec["theta_hom"], theta_het = ParamVec["theta_het_case"])
lrtstat <- -2 * (sum(log(LikTot)) - sum(log(c(LikCTRL, LikCASE))))
LRTpval <- pchisq(lrtstat, df = 1, lower.tail = F)
dAD_res$LRTpval[dAD_res$LocName == LOC] <- LRTpval
# 5. Fill out the results dataframe
dAD_res$QualityCTRL[dAD_res$LocName == LOC] <- # spot bad quality data
OUTfitCTRL$quality; dAD_res$QualityCASE[dAD_res$LocName == LOC] <-OUTfitCASE$quality
# Test HWE on both the control and tumor data:
HWEtest_CTRL <- MAGE::HWE_chisquared(Fmedian = Fmedian, data = OUTfitCTRL_DH)
dAD_res$HWECTRL[dAD_res$LocName == LOC] <- HWEtest_CTRL$PVAL
HWEtest_CASE <- MAGE::HWE_chisquared(Fmedian = Fmedian, data = OUTfitCASE_DH)
dAD_res$HWECASE[dAD_res$LocName == LOC] <- HWEtest_CASE$PVAL
# Mean and median coverages:
dAD_res$CovCTRL_mean[dAD_res$LocName == LOC] <- mean(CTRL_DF[CTRL_DF$Outlier==0,]$ref_count +
CTRL_DF[CTRL_DF$Outlier==0,]$var_count)
dAD_res$CovCASE_mean[dAD_res$LocName == LOC] <- mean(CASE_DF[CASE_DF$Outlier==0,]$ref_count +
CASE_DF[CASE_DF$Outlier==0,]$var_count)
dAD_res$CovCTRL_med[dAD_res$LocName == LOC] <- median(CTRL_DF[CTRL_DF$Outlier==0,]$ref_count +
CTRL_DF[CTRL_DF$Outlier==0,]$var_count)
dAD_res$CovCASE_med[dAD_res$LocName == LOC] <- median(CASE_DF[CASE_DF$Outlier==0,]$ref_count +
CASE_DF[CASE_DF$Outlier==0,]$var_count)
dAD_res$pr[dAD_res$LocName == LOC] <- ParamVec["pr"]; dAD_res$prv[dAD_res$LocName == LOC] <-
ParamVec["prv"]; dAD_res$pv[dAD_res$LocName == LOC] <- ParamVec["pv"]
dAD_res$ThetaHom[dAD_res$LocName == LOC] <- ParamVec["theta_hom"]
}
dAD_res$HWECTRL[is.na(dAD_res$HWECTRL)] <-
dAD_res$HWECTRL[is.na(dAD_res$HWECTRL)] <- -1
dAD_res$RhoH0 <- 1/((1/dAD_res$ThetaH0)+1)
dAD_res$RhoCTRL <- 1/((1/dAD_res$ThetaCTRL_H1)+1)
dAD_res$RhoCASE <- 1/((1/dAD_res$ThetaCASE_H1)+1)
return(dAD_res)
}
cl <- parallel::makeCluster(getOption("cl.cores", NC))
parallel::clusterExport(cl, c("Fmedian", "SEmedian"))
dADFinData <- parallel::parLapply(cl, X = ParTOT, fun = dAD_analysis)
parallel::stopCluster(cl)
dAD_res <- do.call("rbind", dADFinData)
print(paste(dAD_res$LocName[dAD_res$RhoCASE >= 0.1 & p.adjust(dAD_res$LRTpval, method = "BH") < 0.05 &
dAD_res$CovCTRL_med >= 10 & dAD_res$CovCASE_med >= 10 & dAD_res$NumHetCTRL >= 15 &
dAD_res$NumHetCASE >= 15 & dAD_res$HWECTRL >= 0.001 & dAD_res$HWECASE >= 0.001 &
dAD_res$RhoCASE > dAD_res$RhoCTRL], collapse = ", "))
CTRL_DF <- controlList[["loc85"]]
CASE_DF <- caseList[["loc85"]]
PlotData_dAD <- dAD_res[dAD_res$LocName=="loc85",]
dAD_plot1 <- MAGE::MAGE_EMfitplot(ref_counts=CTRL_DF$ref_count, var_counts=CTRL_DF$var_count, pr=PlotData_dAD$pr,
prv=PlotData_dAD$prv, pv=PlotData_dAD$pv, theta_hom = PlotData_dAD$ThetaHom, theta_het = PlotData_dAD$ThetaCTRL_H1,
probshift = PlotData_dAD$PiFitH1, SE = SEmedian, ScaleCount = 50, ScaleHist = TRUE, nbins = 30, plot_NoShift = FALSE)
dAD_plot2 <- MAGE::MAGE_EMfitplot(CASE_DF$ref_count, CASE_DF$var_count, pr=PlotData_dAD$pr, prv=PlotData_dAD$prv,
pv=PlotData_dAD$pv, theta_hom = PlotData_dAD$ThetaHom, theta_het = PlotData_dAD$ThetaCASE_H1,
probshift = PlotData_dAD$PiFitH1, SE = SEmedian, ScaleCount = 50, ScaleHist = TRUE, nbins = 30, plot_NoShift = FALSE)
gridExtra::grid.arrange(dAD_plot1, dAD_plot2, ncol=2)
ChromPlot <- MAGE::MAGE_ADChromplot(AD_Data, DE_Data, Meth_Data, CNAgain_Data, CNAloss_Data, pvalSIG = 0.05, roll_median = 15)
ChromPlot[["ADDE_plot"]] / ChromPlot[["MethCNA_plot"]] / (ChromPlot[["LEG1"]] + ChromPlot[["LEG2"]]
+ ChromPlot[["LEG3"]]) + patchwork::plot_layout(heights = c(2,1,0.5), widths = c(1,1,1))
# Perform filtering using symmetry_gof()
# Notice we use allelefreq_0 as input in this function, which is the allele frequency as estimated by an
# UNSHIFTED binomial mixture model using AllelicMeta_est() earlier in this vignette
# which is what symmetry_GOF assumes as well so it's only fitting.
# We also enforce that this allelefreq_0 can not be more extreme than 0.15 or 0.85,
# because detecting imprinting would be very hard otherwise.
ImprData <- controlList
for(LOC in names(controlList)){
if (ImprData[[LOC]]$allelefreq_0[1] <= 0.15 || ImprData[[LOC]]$allelefreq_0[1] >= (1 - 0.15)) {
ImprData[[LOC]] <- NULL
} else {
ImprData[[LOC]]$sym <- MAGE::symmetry_gof(ImprData[[LOC]]$ref_count, ImprData[[LOC]]$var_count,
ImprData[[LOC]]$allelefreq_0[1])
if (ImprData[[LOC]]$sym[1] <= 0.05) {
ImprData[[LOC]] <- NULL
}
}
}
# Detect imprinted control loci
impr_res <- data.frame()
for(LOC in names(ImprData)){
i_results <- MAGE::imprinting_est(ImprData[[LOC]]$ref_count, ImprData[[LOC]]$var_count,
allelefreq = ImprData[[LOC]]$allelefreq_0[1], SE = SEmedian, inbr = Fmedian)
# An additional robustified "median imprinting" across samples to be used as possible
# additional filter criterion:
med_imp <- MAGE::median_imprinting(ImprData[[LOC]]$ref_count, ImprData[[LOC]]$var_count,
allelefreq = ImprData[[LOC]]$allelefreq_0[1], inbr = Fmedian)
results_z <- data.frame("position" = ImprData[[LOC]]$locus_id[1], "LRT" = i_results$LRT,
"p" = i_results$p_value, "estimated.i" = i_results$est_i, "allele.frequency" =
ImprData[[LOC]]$allelefreq_0[1], "reference" = ImprData[[LOC]]$ref[1], "variant" =
ImprData[[LOC]]$var[1], "med_cov" = ImprData[[LOC]]$coverage[1], "nr_samples" =
nrow(ImprData[[LOC]]), "GOF" = i_results$GOF_likelihood, "symmetry" =
ImprData[[LOC]]$sym[1], "med_impr" = med_imp, stringsAsFactors = FALSE)
impr_res <- rbind(impr_res, results_z)
}
# Retain significantly imprinted loci (5% FDR) utilizing some additional filters, amongst which a custom
# Goodness-Of-Fit which more or less corresponds to a locus' likelihood of the imprinted model*coverage;
# 0.8 is a good cutoff. Other filter criteria are imprinting (0.6) and median imprinting (0.8)
impr_res_FIN <- MAGE::final_filter(data_hash=NULL, impr_res, results_wd=NULL, gof_filt = 0.8,
med_impr_filt = 0.8, i_filt = 0.6, file_all = FALSE, file_impr = FALSE,
file_all_counts = FALSE, file_impr_counts = FALSE)
# From among actually imprinted loci, detect differential expression in case data
pos_impr <- as.character(impr_res_FIN$position)
p_DI_df <- impr_res_FIN
p_DI_df$DI_pval <- 1
for(LOC in pos_impr){
CData <- controlList[[LOC]]
TData <- caseList[[LOC]]
p_DI <- MAGE::LOItest_logreg(CData$ref_count, CData$var_count,
TData$ref_count, TData$var_count)$p.value
p_DI_df$DI_pval[p_DI_df$position == LOC] <- p_DI
}
print(paste(impr_res_FIN$position, collapse = ", "))
print(paste(p_DI_df$position[p.adjust(p_DI_df$DI_pval, method = "holm") < 0.05], collapse = ", "))
HistCTRL <- MAGE::MAGE_imprintplot(controlList[["loc202"]]$ref_count,
controlList[["loc202"]]$var_count,
allelefreq = impr_res_FIN$allele.frequency[impr_res_FIN$position=="loc202"],
impr = impr_res_FIN$estimated.i[impr_res_FIN$position=="loc202"],
SE = SEmedian, inbr = Fmedian, plot_NoImpr = TRUE, SplitPeaks = FALSE) + ggplot2::ggtitle("Control")
RatioCASE <- caseList[["loc202"]]$ref_count /
(caseList[["loc202"]]$ref_count + caseList[["loc202"]]$var_count)
CASEDat <- data.frame("Ratio" = RatioCASE)
HistCASE <- ggplot2::ggplot() + ggplot2::geom_histogram(data = CASEDat, ggplot2::aes(Ratio), bins = 50) +
ggplot2::labs(x="Reference allele fraction", y="Frequency") + ggplot2::ggtitle("Case")
gridExtra::grid.arrange(HistCTRL, HistCASE, ncol=2)
sessionInfo()
MAGE::MAGE_EMfitplot(ref_counts=PlotData$ref_count,
var_counts=PlotData$var_count, pr=PlotData_eqtl$rho_rr, prv=PlotData_eqtl$rho_rv,
pv=PlotData_eqtl$rho_vv, theta_hom=PlotData_eqtl$theta_hom,
theta_het=PlotData_eqtl$theta_het, pr_NoShift=mean(PlotData$prr_H0), prv_NoShift=mean(PlotData$prv_H0),
pv_NoShift=mean(PlotData$pvv_H0), theta_hom_NoShift=PlotData_eqtl$theta_hom_NoShift,
theta_het_NoShift=PlotData_eqtl$theta_het_NoShift, probshift=as.numeric(PlotData_eqtl$probshift),
SE=SEmedian, ScaleCount = PlotData_eqtl$coverage, ScaleHist = TRUE, plot_NoShift = TRUE,
nbins = 30)
options(width = 16)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
ChromPlot <- MAGE::MAGE_ADChromplot(AD_Data, DE_Data, Meth_Data, CNAgain_Data, CNAloss_Data,
pvalSIG = 0.05, roll_median = 15)
ChromPlot[["ADDE_plot"]] / ChromPlot[["MethCNA_plot"]] / (ChromPlot[["LEG1"]] +
ChromPlot[["LEG2"]] + ChromPlot[["LEG3"]]) +
patchwork::plot_layout(heights = c(2,1,0.5), widths = c(0.11,1,1))
data("MAGE", package = "MAGE")
knitr::kable(head(ControlCounts))
ChromPlot <- MAGE::MAGE_ADChromplot(AD_Data, DE_Data, Meth_Data, CNAgain_Data, CNAloss_Data,
pvalSIG = 0.05, roll_median = 15)
ChromPlot[["ADDE_plot"]] / ChromPlot[["MethCNA_plot"]] / (ChromPlot[["LEG1"]] +
ChromPlot[["LEG2"]] + ChromPlot[["LEG3"]]) +
patchwork::plot_layout(heights = c(2,1,0.5), widths = c(0.11,1,1))
ChromPlot <- MAGE::MAGE_ADChromplot(AD_Data, DE_Data, Meth_Data, CNAgain_Data, CNAloss_Data,
pvalSIG = 0.05, roll_median = 15)
ChromPlot[["ADDE_plot"]] / ChromPlot[["MethCNA_plot"]] / (ChromPlot[["LEG1"]] +
ChromPlot[["LEG2"]] + ChromPlot[["LEG3"]]) +
patchwork::plot_layout(heights = c(2,1,0.5), widths = c(0.11,0.11,1))
ChromPlot <- MAGE::MAGE_ADChromplot(AD_Data, DE_Data, Meth_Data, CNAgain_Data, CNAloss_Data,
pvalSIG = 0.05, roll_median = 15)
ChromPlot[["ADDE_plot"]] / ChromPlot[["MethCNA_plot"]] / (ChromPlot[["LEG1"]] +
ChromPlot[["LEG2"]] + ChromPlot[["LEG3"]]) +
patchwork::plot_layout(heights = c(2,1,0.5), widths = c(0.1,0.1,1))
ChromPlot <- MAGE::MAGE_ADChromplot(AD_Data, DE_Data, Meth_Data, CNAgain_Data, CNAloss_Data,
pvalSIG = 0.05, roll_median = 15)
ChromPlot[["ADDE_plot"]] / ChromPlot[["MethCNA_plot"]] / (ChromPlot[["LEG1"]] +
ChromPlot[["LEG2"]] + ChromPlot[["LEG3"]]) +
patchwork::plot_layout(heights = c(2,1,0.5), widths = c(0.1,0.1,1))
load("~/MAGEgenotyper/VignetteRun.RData")
# Statistical evidence for significant AB at the 5% FDR level:
print(paste(Geno_AB_res$position[p.adjust(Geno_AB_res$p, method = "BH") < 0.05 &
Geno_AB_res$quality != "!" & Geno_AB_res$Chi2PVAL >= 0.001], collapse = ", "))
# Statistical evidence for significant AB at the 5% FDR level,
# only retaining reliable (high-quality) loci with a large enough effect size:
print(paste(Geno_AB_res$position[p.adjust(Geno_AB_res$p, method = "BH") < 0.05 &
Geno_AB_res$quality != "!" & (Geno_AB_res$probshift > 0.6 | Geno_AB_res$probshift < 0.4)
& Geno_AB_res$probshift < 0.9 &  Geno_AB_res$probshift > 0.1 & (Geno_AB_res$median_ASE
> 0.6 | Geno_AB_res$median_ASE < 0.4) & Geno_AB_res$allele.frequency < 0.9 &
Geno_AB_res$allele.frequency > 0.2 & Geno_AB_res$coverage > 10 &
Geno_AB_res$nr_samples > 80 & Geno_AB_res$Chi2PVAL >= 0.001], collapse = ", "))
# Statistical evidence for significant AB at the 5% FDR level,
# only retaining reliable (high-quality) loci with a large enough effect size:
print(paste(Geno_AB_res$position[p.adjust(Geno_AB_res$p, method = "BH") < 0.05 &
Geno_AB_res$quality != "!" & (Geno_AB_res$probshift > 0.6 | Geno_AB_res$probshift < 0.4)
& Geno_AB_res$probshift < 0.9 &  Geno_AB_res$probshift > 0.1 & (Geno_AB_res$median_ASE > 0.6 |
Geno_AB_res$median_ASE < 0.4) & Geno_AB_res$allele.frequency < 0.9 &
Geno_AB_res$allele.frequency > 0.2 & Geno_AB_res$coverage > 10 &
Geno_AB_res$nr_samples > 80 & Geno_AB_res$Chi2PVAL >= 0.001], collapse = ", "))
options(width = 16)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
data("MAGE", package = "MAGE")
knitr::kable(head(ControlCounts))
knitr::kable(head(CaseCounts))
length(unique(ControlCounts$locus_id))
sum(ControlCounts$locus_id == "loc1")
# MAGE expects lists:
controlList <- list()
caseList <- list()
for(n in unique(ControlCounts$locus_id)){              # For every locus...
interDF <- ControlCounts[ControlCounts$locus_id==n,] # extract per-sample nucleotide counts
colnames(interDF)[2] <- "ref_alleles"                # re-name the reference_allele column
controlList[[n]] <- interDF                          # put it into the list
}
for(n in unique(CaseCounts$locus_id)){
interDF <- CaseCounts[CaseCounts$locus_id==n,]
colnames(interDF)[2] <- "ref_alleles"
caseList[[n]] <- interDF
}
for(n in names(controlList)){
controlList[[n]] <- MAGE::standard_alleles(controlList[[n]])
}
knitr::kable(head(controlList[["loc27"]]))
for(n in names(caseList)){
interDF <- caseList[[n]]
interDF$ref_alleles <- controlList[[n]]$ref_alleles[1]
interDF$ref <- controlList[[n]]$ref[1]
interDF$var <- controlList[[n]]$var[1]
interDF$ref_count <- interDF[,which(colnames(interDF)==interDF$ref[1])]
interDF$var_count <- interDF[,which(colnames(interDF)==interDF$var[1])]
caseList[[n]] <- interDF
}
for(n in names(controlList)){
controlList[[n]] <- MAGE::prior_filter(controlList[[n]], min_median_cov = 0,
min_nr_samples = 20, checkref_filter = TRUE, prior_allelefreq_filter = FALSE,
min_PriorAlleleFreq = 0)
caseList[[n]] <- MAGE::prior_filter(caseList[[n]], min_median_cov = 0,
min_nr_samples = 0, checkref_filter = FALSE, prior_allelefreq_filter = FALSE,
min_PriorAlleleFreq = 0)
if(is.null(controlList[[n]])){
caseList[[n]] <- NULL
}
}
SE_vec <- c()   # Vector for saving reliable sequencing error rate estimates
F_vec <- c()    # Vector for saving reliable inbreeding coefficient estimates
pA_filt <- 0.15 # Loci with a low minor allele frequency are less reliable
SE_filt <- 0.035 # Loci which return a high estimated sequencing error are suspicious
NumSamp_filt <- 20 # Loci with a lot of samples are reliable for estimating inbreeding
MedianCov_filt <- 4 # Loci with low coverage are unreliable
for(n in names(controlList)){
MetaEst_res <- MAGE::AllelicMeta_est(ref_counts = controlList[[n]]$ref_count,
var_counts = controlList[[n]]$var_count)
# You can store each locus' Sequencing Error (SE) and inbreeding coefficient (F) estimate
# in its dataframe, if you want:
controlList[[n]]$est_SE <- MetaEst_res$SE
controlList[[n]]$est_inbr <- MetaEst_res$F_inbr
controlList[[n]]$allelefreq_0 <- MetaEst_res$allelefreq
# Only take a locus' estimates into account if the locus is high-quality:
if (!(MetaEst_res$allelefreq <= pA_filt || MetaEst_res$allelefreq >= (1 - pA_filt)
# allelefreq returns allele frequency of the ref-allele,
# so just in case this is the minor allele on population level
# (even though it is the most expresse one across all RNAseq data),
# we perform the filtering like this
|| MetaEst_res$SE > SE_filt) & nrow(controlList[[n]])>=NumSamp_filt &
median(controlList[[n]]$ref_count + controlList[[n]]$var_count) >= MedianCov_filt) {
SE_vec <- c(SE_vec, MetaEst_res$SE)
F_vec <- c(F_vec, MetaEst_res$F_inbr)
}
}
SEmedian <- median(SE_vec)
Fmedian <- median(F_vec)
print(c(SEmedian, Fmedian))
NC <- 1 # Number of Cores
NS <- length(controlList)
spl <- c(0, cumsum(rep(floor(NS/NC),NC)+c(rep(1,NS-floor(NS/NC)*NC),
rep(0,NC-NS+floor(NS/NC)*NC)))) # Helps in splitting input data
ParCTRL <- vector(mode = "list", length=NC)
for(i in 1:NC){ # Put the splitted input data into a list for parallellisation
ParCTRL[[i]] <- controlList[(spl[i]+1):(spl[i+1])]
}
BetaBinomGenotyping <- function(data){
positions <- names(data)
results <- data.frame()
for (z in positions) {
MAGEres <- MAGE::EMfit_betabinom_robust(data_counts = data[[z]],
SE = SEmedian, inbr = Fmedian)
data[[z]] <- MAGEres$data_hash
# median_AB also calculates a robust median AB,
# besides the AB as determined during EMfit_betabinom_robust's fitting procedure.
# This can be used as additional filter when detecting significant AB:
med_AB <- MAGE::median_AB(data[[z]]$ref_count, data[[z]]$var_count,
data[[z]]$allelefreq[1], Fmedian)
res_loc <- data.frame("position" = z, "probshift" = as.numeric(MAGEres$AB),
"LRT" = as.numeric(MAGEres$AB_lrt), "p" = as.numeric(MAGEres$AB_p),
"quality" = MAGEres$quality, "allele.frequency" = data[[z]]$allelefreq[1],
"reference" = data[[z]]$ref[1], "variant" = data[[z]]$var[1],
"est_SE" = data[[z]]$est_SE[1], "coverage" = data[[z]]$coverage[1],
"nr_samples" = nrow(data[[z]]), "median_AB" = med_AB,
"rho_rr" = MAGEres$rho_rr, "rho_rv" = MAGEres$rho_rv, "rho_vv" = MAGEres$rho_vv,
"theta_hom" = MAGEres$theta_hom, "theta_het" = MAGEres$theta_het,
"theta_hom_NoShift" = MAGEres$theta_hom_NoShift,
"theta_het_NoShift" = MAGEres$theta_het_NoShift, stringsAsFactors = FALSE)
results <- rbind(results, res_loc) # results; one position per line
}
results <- MAGE::HWE_chisquared(data = data, Fmedian, results = results)
results$Chi2PVAL[is.na(results$Chi2PVAL)] <-
results$Chi2STAT[is.na(results$Chi2STAT)] <- -1
return(list(data, results))
}
cl <- parallel::makeCluster(getOption("cl.cores", NC))
parallel::clusterExport(cl, c("Fmedian", "SEmedian"))
GenoFinData <- parallel::parLapply(cl, X = ParCTRL, fun = BetaBinomGenotyping)
parallel::stopCluster(cl)
ParCTRL <- lapply(GenoFinData, `[[`, 1)
controlList <- do.call(c, lapply(GenoFinData, `[[`, 1))
Geno_AB_res <- do.call("rbind", lapply(GenoFinData, `[[`, 2))
knitr::kable(head(controlList[["loc27"]][,c("locus_id", "sample_id", "ref",
"var", "genotypeN")]))
# Statistical evidence for significant AB at the 5% FDR level:
print(paste(Geno_AB_res$position[p.adjust(Geno_AB_res$p, method = "BH") < 0.05 &
Geno_AB_res$quality != "!" & Geno_AB_res$Chi2PVAL >= 0.001], collapse = ", "))
# Statistical evidence for significant AB at the 5% FDR level,
# only retaining reliable (high-quality) loci with a large enough effect size:
print(paste(Geno_AB_res$position[p.adjust(Geno_AB_res$p, method = "BH") < 0.05 &
Geno_AB_res$quality != "!" & (Geno_AB_res$probshift > 0.6 | Geno_AB_res$probshift < 0.4)
& Geno_AB_res$probshift < 0.9 &  Geno_AB_res$probshift > 0.1 & (Geno_AB_res$median_ASE > 0.6 |
Geno_AB_res$median_ASE < 0.4) & Geno_AB_res$allele.frequency < 0.9 &
Geno_AB_res$allele.frequency > 0.2 & Geno_AB_res$coverage > 10 &
Geno_AB_res$nr_samples > 80 & Geno_AB_res$Chi2PVAL >= 0.001], collapse = ", "))
PlotData <- controlList[["loc11"]]
PlotData_eqtl <- Geno_AB_res[Geno_AB_res$position=="loc11",]
loc_plot <- MAGE::MAGE_EMfitplot(ref_counts=PlotData$ref_count,
var_counts=PlotData$var_count, pr=PlotData_eqtl$rho_rr, prv=PlotData_eqtl$rho_rv,
pv=PlotData_eqtl$rho_vv, theta_hom=PlotData_eqtl$theta_hom,
theta_het=PlotData_eqtl$theta_het, pr_NoShift=mean(PlotData$prr_H0),
prv_NoShift=mean(PlotData$prv_H0), pv_NoShift=mean(PlotData$pvv_H0),
theta_hom_NoShift=PlotData_eqtl$theta_hom_NoShift,
theta_het_NoShift=PlotData_eqtl$theta_het_NoShift,
probshift=as.numeric(PlotData_eqtl$probshift), SE=SEmedian,
ScaleCount = PlotData_eqtl$coverage, ScaleHist = TRUE, plot_NoShift = TRUE, nbins = 30)
loc_plot
loc_plot <- MAGE::MAGE_EMfitplot(ref_counts=PlotData$ref_count,
var_counts=PlotData$var_count, pr=PlotData_eqtl$rho_rr, prv=PlotData_eqtl$rho_rv,
pv=PlotData_eqtl$rho_vv, theta_hom=PlotData_eqtl$theta_hom,
theta_het=PlotData_eqtl$theta_het, pr_NoShift=mean(PlotData$prr_H0),
prv_NoShift=mean(PlotData$prv_H0), pv_NoShift=mean(PlotData$pvv_H0),
theta_hom_NoShift=PlotData_eqtl$theta_hom_NoShift,
theta_het_NoShift=PlotData_eqtl$theta_het_NoShift,
probshift=as.numeric(PlotData_eqtl$probshift), SE=SEmedian,
ScaleCount = PlotData_eqtl$coverage, ScaleHist = TRUE, plot_NoShift = FALSE,
SplitPeaks = FALSE, nbins = 30)
loc_plot
ParCASE <- vector(mode = "list", length=NC)
for(i in 1:NC){ # Put the splitted input data into a list for parallellisation
ParCASE[[i]] <- caseList[(spl[i]+1):(spl[i+1])]
}
ParTOT <- vector(mode = "list", length=NC)
for(i in 1:NC){ # Put the splitted input data into a list for parallellisation
ParTOT[[i]] <- list(ParCTRL[[i]], ParCASE[[i]])
}
dAD_analysis <- function(data){
controlListP <- data[[1]]
caseListP <- data[[2]]
positions <- names(controlListP)
dAD_res <- data.frame(LocName = names(controlListP), PiFitH0 = 0, PiFitH1 = 0, ThetaH0 = 0,
ThetaCTRL_H1 = 0, ThetaCASE_H1 = 0, RhoH0 = 0, RhoCTRL = 0, RhoCASE = 0, LRTpval = 0,
NumHetCTRL = 0, NumHetCASE = 0, RobFlagCTRL = "", RobFlagCASE = "", HWECTRL = 0,
HWECASE = 0, CovCTRL_mean = 0, CovCASE_mean = 0, CovCTRL_med = 0, CovCASE_med = 0,
NumOutCTRL = 0, NumOutCASE = 0, QualityCTRL = "N", QualityCASE = "N", pr = 0,
prv = 0, pv = 0, ThetaHom = 0)
for (LOC in positions) {
CTRL_DF <- data.frame("ref_count" = controlListP[[LOC]]$ref_count,
"var_count" = controlListP[[LOC]]$var_count, "isCase" = 0)
CASE_DF <- data.frame("ref_count" = caseListP[[LOC]]$ref_count,
"var_count" = caseListP[[LOC]]$var_count, "isCase" = 1)
# Previously, we used EMfit_betabinom_robust() to ROBUSTLY fit our models by removing
# outliers via Cook's distance. Now however, we're working with data from two different
# sources (control- and case tissue) and have no way of knowing in advance how similar
# these are. As such, outlier detections should happen ON BOTH SETS SEPARATELY yet the
# two hypotheses we'll be fitting share all or some parameters between the two.
# For this, we can use the EMfit_betabinom_robust() function with its "fitH0" set to
# FALSE, which will not complete the entire eqtl-detection pipeline, but will cut it
# short before fitting the unshifted model. By running this function on both our
# datasets separately in advance of the dAD-relevant fits, we ensure correct outlier
# detection Ã¡nd the use of the same dataset in our upcoming likelihood ratio tests.
# 1. Detect and extract outliers using EMfit_betabinom_robust()
OUTfitCTRL <- MAGE::EMfit_betabinom_robust(data_counts = CTRL_DF, SE = SEmedian,
inbr = Fmedian, fitH0 = FALSE)
OUTfitCASE <- MAGE::EMfit_betabinom_robust(data_counts = CASE_DF, SE = SEmedian,
inbr = Fmedian, fitH0 = FALSE)
OUTfitCTRL_DH <- OUTfitCTRL$data_hash; OUTfitCASE_DH <- OUTfitCASE$data_hash
CTRL_DF$Outlier <- OUTfitCTRL_DH$Outlier; CASE_DF$Outlier <- OUTfitCASE_DH$Outlier
CurDF <- rbind(CTRL_DF, CASE_DF)
# These results are also handy for an estimation of the number of heterozygotes in
# controls and tumors AND the number of outliers, both good filter criteria.
# We can also include a "RobFlag" which gives more information about outlier detection
# (e.g. none detected, or so unreasonably many that none were removed)
dAD_res$NumHetCTRL[dAD_res$LocName == LOC] <- sum(OUTfitCTRL_DH$prv)
dAD_res$NumHetCASE[dAD_res$LocName == LOC] <- sum(OUTfitCASE_DH$prv)
dAD_res$NumOutCTRL[dAD_res$LocName == LOC] <- sum(CTRL_DF$Outlier)
dAD_res$NumOutCASE[dAD_res$LocName == LOC] <- sum(CASE_DF$Outlier)
dAD_res$RobFlagCTRL[dAD_res$LocName == LOC] <- OUTfitCTRL$RobFlag
dAD_res$RobFlagCASE[dAD_res$LocName == LOC] <- OUTfitCASE$RobFlag
# 2. Perform one fit on the entire (non-outlying) data, i.e. all parameters shared,
# i.e. assuming no dAD; the null hypothesis in dAD detection.
# Remark this uses the non-robust fitting function, since outliers were already detected.
NOdAD_fit <- MAGE::EMfit_betabinom(data_counts = CurDF[CurDF$Outlier == 0,],
SE = SEmedian, inbr = Fmedian, fitH0 = FALSE)
NOdAD_fit_DF <- NOdAD_fit$data_hash
PiH0 <- NOdAD_fit$AB
rho_rr <- NOdAD_fit$rho_rr; rho_rv <- NOdAD_fit$rho_rv; rho_vv <- NOdAD_fit$rho_vv
ThetaHomH0 <- NOdAD_fit$theta_hom; ThetaHetH0 <- NOdAD_fit$theta_het
dAD_res$PiFitH0[dAD_res$LocName == LOC] <- PiH0
dAD_res$ThetaH0[dAD_res$LocName == LOC] <- ThetaHetH0
# 3. Perform a fit on the (non-outlying) data allowing separate theta_het parameters
# for control- and case-data
FullFit <- MAGE::EMfit_betabinom_popcomb(data_counts = CurDF[CurDF$Outlier == 0,],
SE = SEmedian, inbr = Fmedian, probshift_init = PiH0)
ParamVec <- FullFit$ParamVec
dAD_res$PiFitH1[dAD_res$LocName == LOC] <- ParamVec["probshift"]
dAD_res$ThetaCTRL_H1[dAD_res$LocName == LOC] <- ParamVec["theta_het_control"]
dAD_res$ThetaCASE_H1[dAD_res$LocName == LOC] <- ParamVec["theta_het_case"]
# 4. Perform the Likelihood Ratio Test for dAD detection
# Likelihood of fit with all parameters shared:
LikTot <- MAGE::pmf_betabinomMix(CurDF[CurDF$Outlier==0,]$ref_count,
CurDF[CurDF$Outlier==0,]$var_count, probshift = PiH0, SEmedian, rho_rr, rho_vv, rho_rv,
theta_hom = ThetaHomH0, theta_het = ThetaHetH0)
# Likelihood of fit with separate theta_het (calculated in two steps because of the
# different theta)
LikCTRL <- MAGE::pmf_betabinomMix(CTRL_DF[CTRL_DF$Outlier==0,]$ref_count,
CTRL_DF[CTRL_DF$Outlier==0,]$var_count, probshift = ParamVec["probshift"], SEmedian,
ParamVec["pr"], ParamVec["pv"], ParamVec["prv"], theta_hom = ParamVec["theta_hom"],
theta_het = ParamVec["theta_het_control"])
LikCASE <- MAGE::pmf_betabinomMix(CASE_DF[CASE_DF$Outlier==0,]$ref_count,
CASE_DF[CASE_DF$Outlier==0,]$var_count, probshift = ParamVec["probshift"], SEmedian,
ParamVec["pr"], ParamVec["pv"], ParamVec["prv"], theta_hom = ParamVec["theta_hom"],
theta_het = ParamVec["theta_het_case"])
lrtstat <- -2 * (sum(log(LikTot)) - sum(log(c(LikCTRL, LikCASE))))
LRTpval <- pchisq(lrtstat, df = 1, lower.tail = F)
dAD_res$LRTpval[dAD_res$LocName == LOC] <- LRTpval
# 5. Fill out the results dataframe
dAD_res$QualityCTRL[dAD_res$LocName == LOC] <- # spot bad quality data
OUTfitCTRL$quality; dAD_res$QualityCASE[dAD_res$LocName == LOC] <-OUTfitCASE$quality
# Test HWE on both the control and tumor data:
HWEtest_CTRL <- MAGE::HWE_chisquared(Fmedian = Fmedian, data = OUTfitCTRL_DH)
dAD_res$HWECTRL[dAD_res$LocName == LOC] <- HWEtest_CTRL$PVAL
HWEtest_CASE <- MAGE::HWE_chisquared(Fmedian = Fmedian, data = OUTfitCASE_DH)
dAD_res$HWECASE[dAD_res$LocName == LOC] <- HWEtest_CASE$PVAL
# Mean and median coverages:
dAD_res$CovCTRL_mean[dAD_res$LocName == LOC] <-
mean(CTRL_DF[CTRL_DF$Outlier==0,]$ref_count + CTRL_DF[CTRL_DF$Outlier==0,]$var_count)
dAD_res$CovCASE_mean[dAD_res$LocName == LOC] <-
mean(CASE_DF[CASE_DF$Outlier==0,]$ref_count + CASE_DF[CASE_DF$Outlier==0,]$var_count)
dAD_res$CovCTRL_med[dAD_res$LocName == LOC] <-
median(CTRL_DF[CTRL_DF$Outlier==0,]$ref_count + CTRL_DF[CTRL_DF$Outlier==0,]$var_count)
dAD_res$CovCASE_med[dAD_res$LocName == LOC] <-
median(CASE_DF[CASE_DF$Outlier==0,]$ref_count + CASE_DF[CASE_DF$Outlier==0,]$var_count)
dAD_res$pr[dAD_res$LocName == LOC] <- ParamVec["pr"]
dAD_res$prv[dAD_res$LocName == LOC] <- ParamVec["prv"]
dAD_res$pv[dAD_res$LocName == LOC] <- ParamVec["pv"]
dAD_res$ThetaHom[dAD_res$LocName == LOC] <- ParamVec["theta_hom"]
}
dAD_res$HWECTRL[is.na(dAD_res$HWECTRL)] <-
dAD_res$HWECTRL[is.na(dAD_res$HWECTRL)] <- -1
dAD_res$RhoH0 <- 1/((1/dAD_res$ThetaH0)+1)
dAD_res$RhoCTRL <- 1/((1/dAD_res$ThetaCTRL_H1)+1)
dAD_res$RhoCASE <- 1/((1/dAD_res$ThetaCASE_H1)+1)
return(dAD_res)
}
cl <- parallel::makeCluster(getOption("cl.cores", NC))
parallel::clusterExport(cl, c("Fmedian", "SEmedian"))
dADFinData <- parallel::parLapply(cl, X = ParTOT, fun = dAD_analysis)
# Statistical evidence for significant AB at the 5% FDR level,
# only retaining reliable (high-quality) loci with a large enough effect size:
print(paste(Geno_AB_res$position[p.adjust(Geno_AB_res$p, method = "BH") < 0.05 &
Geno_AB_res$quality != "!" & (Geno_AB_res$probshift > 0.6 | Geno_AB_res$probshift < 0.4)
& Geno_AB_res$probshift < 0.9 &  Geno_AB_res$probshift > 0.1 & (Geno_AB_res$median_ASE > 0.6 |
Geno_AB_res$median_ASE < 0.4) & Geno_AB_res$allele.frequency < 0.9 &
Geno_AB_res$allele.frequency > 0.2 & Geno_AB_res$coverage > 10 &
Geno_AB_res$nr_samples > 80 & Geno_AB_res$Chi2PVAL >= 0.001], collapse = ", "))
# Statistical evidence for significant AB at the 5% FDR level:
print(paste(Geno_AB_res$position[p.adjust(Geno_AB_res$p, method = "BH") < 0.05 &
Geno_AB_res$quality != "!" & Geno_AB_res$Chi2PVAL >= 0.001], collapse = ", "))
sum(Geno_AB_res$position[p.adjust(Geno_AB_res$p, method = "BH") < 0.05)
sum(p.adjust(Geno_AB_res$p, method = "BH") < 0.05)
sum(Geno_AB_res$quality != "!")
sum(Geno_AB_res$probshift > 0.6 | Geno_AB_res$probshift < 0.4)
sum(Geno_AB_res$probshift < 0.9)
sum(Geno_AB_res$probshift > 0.1 )
sum(Geno_AB_res$median_ASE > 0.6)
# Statistical evidence for significant AB at the 5% FDR level,
# only retaining reliable (high-quality) loci with a large enough effect size:
print(paste(Geno_AB_res$position[p.adjust(Geno_AB_res$p, method = "BH") < 0.05 &
Geno_AB_res$quality != "!" & (Geno_AB_res$probshift > 0.6 | Geno_AB_res$probshift < 0.4)
& Geno_AB_res$probshift < 0.9 &  Geno_AB_res$probshift > 0.1 & (Geno_AB_res$median_AB > 0.6 |
Geno_AB_res$median_AB < 0.4) & Geno_AB_res$allele.frequency < 0.9 &
Geno_AB_res$allele.frequency > 0.2 & Geno_AB_res$coverage > 10 &
Geno_AB_res$nr_samples > 80 & Geno_AB_res$Chi2PVAL >= 0.001], collapse = ", "))
